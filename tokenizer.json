"{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": 20000, \"filters\": \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<OOV>\", \"document_count\": 9, \"word_counts\": \"{\\\"s\\\": 1, \\\"t\\\": 3, \\\"a\\\": 1, \\\"e\\\": 2, \\\"m\\\": 1, \\\"n\\\": 1}\", \"word_docs\": \"{\\\"s\\\": 1, \\\"t\\\": 3, \\\"a\\\": 1, \\\"e\\\": 2, \\\"m\\\": 1, \\\"n\\\": 1}\", \"index_docs\": \"{\\\"4\\\": 1, \\\"2\\\": 3, \\\"5\\\": 1, \\\"3\\\": 2, \\\"6\\\": 1, \\\"7\\\": 1}\", \"index_word\": \"{\\\"1\\\": \\\"<OOV>\\\", \\\"2\\\": \\\"t\\\", \\\"3\\\": \\\"e\\\", \\\"4\\\": \\\"s\\\", \\\"5\\\": \\\"a\\\", \\\"6\\\": \\\"m\\\", \\\"7\\\": \\\"n\\\"}\", \"word_index\": \"{\\\"<OOV>\\\": 1, \\\"t\\\": 2, \\\"e\\\": 3, \\\"s\\\": 4, \\\"a\\\": 5, \\\"m\\\": 6, \\\"n\\\": 7}\"}}"